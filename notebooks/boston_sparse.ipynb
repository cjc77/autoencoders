{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras.regularizers import l1\n",
    "from keras.datasets import boston_housing\n",
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X, eps=1e-10):\n",
    "    m = X.mean(axis=0, keepdims=True)\n",
    "    s = X.std(axis=0, keepdims=True)\n",
    "    s[np.where(s == 0)] = eps\n",
    "    return (X - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "X_train = normalize(X_train, axis=0)\n",
    "X_test = normalize(X_test, axis=0)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "\n",
    "d = X_train.shape[1]\n",
    "# enc_d = 32\n",
    "enc_d = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 404 samples, validate on 102 samples\nEpoch 1/50\n404/404 [==============================] - 1s 1ms/step - loss: 602.4036 - accuracy: 0.0000e+00 - val_loss: 617.4592 - val_accuracy: 0.0000e+00\nEpoch 2/50\n404/404 [==============================] - 0s 116us/step - loss: 597.2856 - accuracy: 0.0000e+00 - val_loss: 615.7508 - val_accuracy: 0.0000e+00\nEpoch 3/50\n404/404 [==============================] - 0s 119us/step - loss: 594.0826 - accuracy: 0.0000e+00 - val_loss: 614.4809 - val_accuracy: 0.0000e+00\nEpoch 4/50\n404/404 [==============================] - 0s 124us/step - loss: 591.4284 - accuracy: 0.0000e+00 - val_loss: 613.4358 - val_accuracy: 0.0000e+00\nEpoch 5/50\n404/404 [==============================] - 0s 119us/step - loss: 589.0320 - accuracy: 0.0000e+00 - val_loss: 612.3980 - val_accuracy: 0.0000e+00\nEpoch 6/50\n404/404 [==============================] - 0s 116us/step - loss: 586.6622 - accuracy: 0.0000e+00 - val_loss: 611.3305 - val_accuracy: 0.0000e+00\nEpoch 7/50\n404/404 [==============================] - 0s 136us/step - loss: 583.8530 - accuracy: 0.0000e+00 - val_loss: 610.1516 - val_accuracy: 0.0000e+00\nEpoch 8/50\n404/404 [==============================] - 0s 124us/step - loss: 580.9720 - accuracy: 0.0000e+00 - val_loss: 608.8530 - val_accuracy: 0.0000e+00\nEpoch 9/50\n404/404 [==============================] - 0s 121us/step - loss: 578.2222 - accuracy: 0.0000e+00 - val_loss: 607.5986 - val_accuracy: 0.0000e+00\nEpoch 10/50\n404/404 [==============================] - 0s 116us/step - loss: 575.8105 - accuracy: 0.0000e+00 - val_loss: 606.2513 - val_accuracy: 0.0000e+00\nEpoch 11/50\n404/404 [==============================] - 0s 124us/step - loss: 573.4277 - accuracy: 0.0000e+00 - val_loss: 604.6491 - val_accuracy: 0.0000e+00\nEpoch 12/50\n404/404 [==============================] - 0s 121us/step - loss: 570.7909 - accuracy: 0.0000e+00 - val_loss: 602.8632 - val_accuracy: 0.0000e+00\nEpoch 13/50\n404/404 [==============================] - 0s 124us/step - loss: 568.0174 - accuracy: 0.0000e+00 - val_loss: 600.9499 - val_accuracy: 0.0000e+00\nEpoch 14/50\n404/404 [==============================] - 0s 126us/step - loss: 565.0046 - accuracy: 0.0000e+00 - val_loss: 598.8882 - val_accuracy: 0.0000e+00\nEpoch 15/50\n404/404 [==============================] - 0s 121us/step - loss: 561.6034 - accuracy: 0.0000e+00 - val_loss: 596.5554 - val_accuracy: 0.0000e+00\nEpoch 16/50\n404/404 [==============================] - 0s 119us/step - loss: 557.5699 - accuracy: 0.0000e+00 - val_loss: 594.1259 - val_accuracy: 0.0000e+00\nEpoch 17/50\n404/404 [==============================] - 0s 124us/step - loss: 553.7345 - accuracy: 0.0000e+00 - val_loss: 591.2602 - val_accuracy: 0.0000e+00\nEpoch 18/50\n404/404 [==============================] - 0s 121us/step - loss: 549.0299 - accuracy: 0.0000e+00 - val_loss: 588.3057 - val_accuracy: 0.0000e+00\nEpoch 19/50\n404/404 [==============================] - 0s 129us/step - loss: 544.0159 - accuracy: 0.0000e+00 - val_loss: 584.6664 - val_accuracy: 0.0000e+00\nEpoch 20/50\n404/404 [==============================] - 0s 136us/step - loss: 537.8226 - accuracy: 0.0000e+00 - val_loss: 580.6558 - val_accuracy: 0.0000e+00\nEpoch 21/50\n404/404 [==============================] - 0s 136us/step - loss: 531.7389 - accuracy: 0.0000e+00 - val_loss: 575.9678 - val_accuracy: 0.0000e+00\nEpoch 22/50\n404/404 [==============================] - 0s 126us/step - loss: 523.6667 - accuracy: 0.0000e+00 - val_loss: 569.5572 - val_accuracy: 0.0000e+00\nEpoch 23/50\n404/404 [==============================] - 0s 126us/step - loss: 513.9612 - accuracy: 0.0000e+00 - val_loss: 561.0559 - val_accuracy: 0.0000e+00\nEpoch 24/50\n404/404 [==============================] - 0s 131us/step - loss: 503.9833 - accuracy: 0.0000e+00 - val_loss: 551.6875 - val_accuracy: 0.0000e+00\nEpoch 25/50\n404/404 [==============================] - 0s 126us/step - loss: 493.5225 - accuracy: 0.0000e+00 - val_loss: 542.4109 - val_accuracy: 0.0000e+00\nEpoch 26/50\n404/404 [==============================] - 0s 121us/step - loss: 481.6033 - accuracy: 0.0000e+00 - val_loss: 532.4967 - val_accuracy: 0.0000e+00\nEpoch 27/50\n404/404 [==============================] - 0s 121us/step - loss: 471.6573 - accuracy: 0.0000e+00 - val_loss: 521.1983 - val_accuracy: 0.0000e+00\nEpoch 28/50\n404/404 [==============================] - 0s 124us/step - loss: 457.6766 - accuracy: 0.0000e+00 - val_loss: 508.3504 - val_accuracy: 0.0000e+00\nEpoch 29/50\n404/404 [==============================] - 0s 121us/step - loss: 445.4211 - accuracy: 0.0000e+00 - val_loss: 494.5607 - val_accuracy: 0.0000e+00\nEpoch 30/50\n404/404 [==============================] - 0s 124us/step - loss: 432.0417 - accuracy: 0.0000e+00 - val_loss: 479.8039 - val_accuracy: 0.0000e+00\nEpoch 31/50\n404/404 [==============================] - 0s 124us/step - loss: 417.6411 - accuracy: 0.0000e+00 - val_loss: 463.6381 - val_accuracy: 0.0000e+00\nEpoch 32/50\n404/404 [==============================] - 0s 126us/step - loss: 400.9273 - accuracy: 0.0000e+00 - val_loss: 447.3104 - val_accuracy: 0.0000e+00\nEpoch 33/50\n404/404 [==============================] - 0s 126us/step - loss: 384.8688 - accuracy: 0.0000e+00 - val_loss: 432.2722 - val_accuracy: 0.0000e+00\nEpoch 34/50\n404/404 [==============================] - 0s 124us/step - loss: 368.6092 - accuracy: 0.0000e+00 - val_loss: 415.6065 - val_accuracy: 0.0000e+00\nEpoch 35/50\n404/404 [==============================] - 0s 121us/step - loss: 352.7830 - accuracy: 0.0000e+00 - val_loss: 396.8461 - val_accuracy: 0.0000e+00\nEpoch 36/50\n404/404 [==============================] - 0s 121us/step - loss: 338.1883 - accuracy: 0.0000e+00 - val_loss: 377.1102 - val_accuracy: 0.0000e+00\nEpoch 37/50\n404/404 [==============================] - 0s 124us/step - loss: 321.0620 - accuracy: 0.0000e+00 - val_loss: 354.1901 - val_accuracy: 0.0000e+00\nEpoch 38/50\n404/404 [==============================] - 0s 124us/step - loss: 306.4249 - accuracy: 0.0000e+00 - val_loss: 336.0363 - val_accuracy: 0.0000e+00\nEpoch 39/50\n404/404 [==============================] - 0s 124us/step - loss: 293.2144 - accuracy: 0.0000e+00 - val_loss: 319.8971 - val_accuracy: 0.0000e+00\nEpoch 40/50\n404/404 [==============================] - 0s 119us/step - loss: 276.1702 - accuracy: 0.0000e+00 - val_loss: 300.5081 - val_accuracy: 0.0000e+00\nEpoch 41/50\n404/404 [==============================] - 0s 134us/step - loss: 260.2554 - accuracy: 0.0000e+00 - val_loss: 283.4585 - val_accuracy: 0.0000e+00\nEpoch 42/50\n404/404 [==============================] - 0s 126us/step - loss: 246.4350 - accuracy: 0.0000e+00 - val_loss: 265.6800 - val_accuracy: 0.0000e+00\nEpoch 43/50\n404/404 [==============================] - 0s 121us/step - loss: 233.2050 - accuracy: 0.0000e+00 - val_loss: 248.4068 - val_accuracy: 0.0000e+00\nEpoch 44/50\n404/404 [==============================] - 0s 126us/step - loss: 218.1856 - accuracy: 0.0000e+00 - val_loss: 236.3119 - val_accuracy: 0.0000e+00\nEpoch 45/50\n404/404 [==============================] - 0s 124us/step - loss: 207.3258 - accuracy: 0.0000e+00 - val_loss: 229.9738 - val_accuracy: 0.0000e+00\nEpoch 46/50\n404/404 [==============================] - 0s 121us/step - loss: 197.7226 - accuracy: 0.0000e+00 - val_loss: 214.2836 - val_accuracy: 0.0000e+00\nEpoch 47/50\n404/404 [==============================] - 0s 119us/step - loss: 190.9302 - accuracy: 0.0050 - val_loss: 204.4305 - val_accuracy: 0.0000e+00\nEpoch 48/50\n404/404 [==============================] - 0s 119us/step - loss: 175.5694 - accuracy: 0.0025 - val_loss: 193.4082 - val_accuracy: 0.0098\nEpoch 49/50\n404/404 [==============================] - 0s 121us/step - loss: 166.3716 - accuracy: 0.0025 - val_loss: 178.3289 - val_accuracy: 0.0000e+00\nEpoch 50/50\n404/404 [==============================] - 0s 121us/step - loss: 154.4792 - accuracy: 0.0050 - val_loss: 168.2731 - val_accuracy: 0.0196\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=d, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 404 samples, validate on 102 samples\nEpoch 1/50\n404/404 [==============================] - 0s 352us/step - loss: 0.6897 - accuracy: 0.0550 - val_loss: 0.6851 - val_accuracy: 0.0490\nEpoch 2/50\n404/404 [==============================] - 0s 89us/step - loss: 0.6787 - accuracy: 0.1015 - val_loss: 0.6733 - val_accuracy: 0.0777\nEpoch 3/50\n404/404 [==============================] - 0s 89us/step - loss: 0.6641 - accuracy: 0.1161 - val_loss: 0.6548 - val_accuracy: 0.0897\nEpoch 4/50\n404/404 [==============================] - 0s 92us/step - loss: 0.6370 - accuracy: 0.1150 - val_loss: 0.6157 - val_accuracy: 0.1176\nEpoch 5/50\n404/404 [==============================] - 0s 87us/step - loss: 0.5774 - accuracy: 0.1266 - val_loss: 0.5324 - val_accuracy: 0.1237\nEpoch 6/50\n404/404 [==============================] - 0s 84us/step - loss: 0.4630 - accuracy: 0.1293 - val_loss: 0.4087 - val_accuracy: 0.1237\nEpoch 7/50\n404/404 [==============================] - 0s 84us/step - loss: 0.3247 - accuracy: 0.1293 - val_loss: 0.3162 - val_accuracy: 0.1237\nEpoch 8/50\n404/404 [==============================] - 0s 84us/step - loss: 0.2322 - accuracy: 0.1293 - val_loss: 0.2840 - val_accuracy: 0.1237\nEpoch 9/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1914 - accuracy: 0.1293 - val_loss: 0.2802 - val_accuracy: 0.1237\nEpoch 10/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1756 - accuracy: 0.1293 - val_loss: 0.2837 - val_accuracy: 0.1237\nEpoch 11/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1691 - accuracy: 0.1293 - val_loss: 0.2881 - val_accuracy: 0.1237\nEpoch 12/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1662 - accuracy: 0.1293 - val_loss: 0.2917 - val_accuracy: 0.1237\nEpoch 13/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1648 - accuracy: 0.1293 - val_loss: 0.2944 - val_accuracy: 0.1237\nEpoch 14/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1641 - accuracy: 0.1293 - val_loss: 0.2963 - val_accuracy: 0.1237\nEpoch 15/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1636 - accuracy: 0.1293 - val_loss: 0.2975 - val_accuracy: 0.1237\nEpoch 16/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1634 - accuracy: 0.1293 - val_loss: 0.2983 - val_accuracy: 0.1237\nEpoch 17/50\n404/404 [==============================] - 0s 94us/step - loss: 0.1632 - accuracy: 0.1293 - val_loss: 0.2988 - val_accuracy: 0.1237\nEpoch 18/50\n404/404 [==============================] - 0s 84us/step - loss: 0.1630 - accuracy: 0.1293 - val_loss: 0.2992 - val_accuracy: 0.1237\nEpoch 19/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1629 - accuracy: 0.1293 - val_loss: 0.2993 - val_accuracy: 0.1237\nEpoch 20/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1628 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 21/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1628 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 22/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1627 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 23/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1627 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 24/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1626 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 25/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1626 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 26/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1626 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 27/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1626 - accuracy: 0.1293 - val_loss: 0.2997 - val_accuracy: 0.1237\nEpoch 28/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1626 - accuracy: 0.1293 - val_loss: 0.2997 - val_accuracy: 0.1237\nEpoch 29/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 30/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2994 - val_accuracy: 0.1237\nEpoch 31/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 32/50\n404/404 [==============================] - 0s 94us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 33/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2996 - val_accuracy: 0.1237\nEpoch 34/50\n404/404 [==============================] - 0s 84us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2993 - val_accuracy: 0.1237\nEpoch 35/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 36/50\n404/404 [==============================] - 0s 94us/step - loss: 0.1625 - accuracy: 0.1293 - val_loss: 0.2995 - val_accuracy: 0.1237\nEpoch 37/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2994 - val_accuracy: 0.1237\nEpoch 38/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2992 - val_accuracy: 0.1237\nEpoch 39/50\n404/404 [==============================] - 0s 97us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2992 - val_accuracy: 0.1237\nEpoch 40/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2992 - val_accuracy: 0.1237\nEpoch 41/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2991 - val_accuracy: 0.1237\nEpoch 42/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2991 - val_accuracy: 0.1237\nEpoch 43/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2991 - val_accuracy: 0.1237\nEpoch 44/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2990 - val_accuracy: 0.1237\nEpoch 45/50\n404/404 [==============================] - 0s 84us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2988 - val_accuracy: 0.1237\nEpoch 46/50\n404/404 [==============================] - 0s 89us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2987 - val_accuracy: 0.1237\nEpoch 47/50\n404/404 [==============================] - 0s 87us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2987 - val_accuracy: 0.1237\nEpoch 48/50\n404/404 [==============================] - 0s 92us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2986 - val_accuracy: 0.1237\nEpoch 49/50\n404/404 [==============================] - 0s 104us/step - loss: 0.1624 - accuracy: 0.1293 - val_loss: 0.2984 - val_accuracy: 0.1237\nEpoch 50/50\n404/404 [==============================] - 0s 94us/step - loss: 0.1623 - accuracy: 0.1293 - val_loss: 0.2984 - val_accuracy: 0.1237\n"
    }
   ],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(Dense(enc_d, input_dim=d, activation=\"relu\", activity_regularizer=l1(10e-5)))\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(d, activation=\"sigmoid\", input_dim=enc_d))\n",
    "\n",
    "auto_enc = Sequential()\n",
    "auto_enc.add(encoder)\n",
    "auto_enc.add(decoder)\n",
    "auto_enc.compile(optimizer=\"adadelta\", loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "hist = auto_enc.fit(X_train, X_train, batch_size=32, epochs=50, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_est = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.6727468 , 0.27171284, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 2.3693194 , 1.249168  , 0.        ,\n       0.11553927, 1.2314316 , 0.08897564], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_est[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}