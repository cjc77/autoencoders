{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras.regularizers import l1\n",
    "from keras.datasets import boston_housing\n",
    "# from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X, eps=1e-10):\n",
    "    m = X.mean(axis=0, keepdims=True)\n",
    "    s = X.std(axis=0, keepdims=True)\n",
    "    s[np.where(s == 0)] = eps\n",
    "    return (X - m) / s\n",
    "\n",
    "\n",
    "def normalize(X, eps=1e-10):\n",
    "    mn = X.min(axis=0, keepdims=True)\n",
    "    mx = X.max(axis=0, keepdims=True)\n",
    "    diff = mx - mn\n",
    "    diff[np.where(diff == 0)] = eps\n",
    "    return (X - mn) / (mx - mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "\n",
    "d = X_train.shape[1]\n",
    "# enc_d = 32\n",
    "enc_d = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 404 samples, validate on 102 samples\nEpoch 1/50\n404/404 [==============================] - 1s 1ms/step - loss: 597.9693 - val_loss: 630.7644\nEpoch 2/50\n404/404 [==============================] - 0s 104us/step - loss: 588.7445 - val_loss: 627.6167\nEpoch 3/50\n404/404 [==============================] - 0s 109us/step - loss: 580.5140 - val_loss: 624.9766\nEpoch 4/50\n404/404 [==============================] - 0s 109us/step - loss: 573.8225 - val_loss: 622.4166\nEpoch 5/50\n404/404 [==============================] - 0s 106us/step - loss: 567.2196 - val_loss: 620.0293\nEpoch 6/50\n404/404 [==============================] - 0s 114us/step - loss: 560.8313 - val_loss: 617.4960\nEpoch 7/50\n404/404 [==============================] - 0s 116us/step - loss: 554.2473 - val_loss: 614.3205\nEpoch 8/50\n404/404 [==============================] - 0s 114us/step - loss: 546.7198 - val_loss: 610.1485\nEpoch 9/50\n404/404 [==============================] - 0s 109us/step - loss: 538.6788 - val_loss: 604.4006\nEpoch 10/50\n404/404 [==============================] - 0s 114us/step - loss: 530.2093 - val_loss: 597.6115\nEpoch 11/50\n404/404 [==============================] - 0s 111us/step - loss: 521.4646 - val_loss: 589.5413\nEpoch 12/50\n404/404 [==============================] - 0s 116us/step - loss: 513.6554 - val_loss: 579.9621\nEpoch 13/50\n404/404 [==============================] - 0s 111us/step - loss: 502.4210 - val_loss: 568.2928\nEpoch 14/50\n404/404 [==============================] - 0s 109us/step - loss: 491.2760 - val_loss: 556.1840\nEpoch 15/50\n404/404 [==============================] - 0s 106us/step - loss: 479.4186 - val_loss: 542.5764\nEpoch 16/50\n404/404 [==============================] - 0s 116us/step - loss: 466.3922 - val_loss: 527.5458\nEpoch 17/50\n404/404 [==============================] - 0s 114us/step - loss: 452.5610 - val_loss: 511.1280\nEpoch 18/50\n404/404 [==============================] - 0s 109us/step - loss: 438.7164 - val_loss: 494.6454\nEpoch 19/50\n404/404 [==============================] - 0s 109us/step - loss: 423.1903 - val_loss: 475.1486\nEpoch 20/50\n404/404 [==============================] - 0s 111us/step - loss: 407.3865 - val_loss: 455.5668\nEpoch 21/50\n404/404 [==============================] - 0s 114us/step - loss: 390.1735 - val_loss: 434.1826\nEpoch 22/50\n404/404 [==============================] - 0s 119us/step - loss: 372.8410 - val_loss: 414.4481\nEpoch 23/50\n404/404 [==============================] - 0s 121us/step - loss: 355.7472 - val_loss: 389.6395\nEpoch 24/50\n404/404 [==============================] - 0s 119us/step - loss: 339.3268 - val_loss: 366.9974\nEpoch 25/50\n404/404 [==============================] - 0s 121us/step - loss: 317.8840 - val_loss: 345.1522\nEpoch 26/50\n404/404 [==============================] - 0s 106us/step - loss: 299.1367 - val_loss: 323.3081\nEpoch 27/50\n404/404 [==============================] - 0s 116us/step - loss: 283.1390 - val_loss: 301.0576\nEpoch 28/50\n404/404 [==============================] - 0s 121us/step - loss: 263.4508 - val_loss: 281.0534\nEpoch 29/50\n404/404 [==============================] - 0s 126us/step - loss: 248.2673 - val_loss: 262.8158\nEpoch 30/50\n404/404 [==============================] - 0s 116us/step - loss: 231.3054 - val_loss: 246.0807\nEpoch 31/50\n404/404 [==============================] - 0s 114us/step - loss: 214.7161 - val_loss: 230.1275\nEpoch 32/50\n404/404 [==============================] - 0s 114us/step - loss: 201.3013 - val_loss: 215.9803\nEpoch 33/50\n404/404 [==============================] - 0s 119us/step - loss: 188.7283 - val_loss: 202.6680\nEpoch 34/50\n404/404 [==============================] - 0s 114us/step - loss: 175.2408 - val_loss: 190.3654\nEpoch 35/50\n404/404 [==============================] - 0s 116us/step - loss: 165.1470 - val_loss: 180.2964\nEpoch 36/50\n404/404 [==============================] - 0s 111us/step - loss: 153.2285 - val_loss: 171.8798\nEpoch 37/50\n404/404 [==============================] - 0s 116us/step - loss: 144.7367 - val_loss: 163.9172\nEpoch 38/50\n404/404 [==============================] - 0s 111us/step - loss: 139.9508 - val_loss: 154.6997\nEpoch 39/50\n404/404 [==============================] - 0s 109us/step - loss: 130.7585 - val_loss: 143.6318\nEpoch 40/50\n404/404 [==============================] - 0s 109us/step - loss: 121.5188 - val_loss: 134.8861\nEpoch 41/50\n404/404 [==============================] - 0s 114us/step - loss: 118.6985 - val_loss: 127.2847\nEpoch 42/50\n404/404 [==============================] - 0s 114us/step - loss: 113.3989 - val_loss: 121.5287\nEpoch 43/50\n404/404 [==============================] - 0s 114us/step - loss: 104.0410 - val_loss: 116.6347\nEpoch 44/50\n404/404 [==============================] - 0s 116us/step - loss: 105.3365 - val_loss: 112.8399\nEpoch 45/50\n404/404 [==============================] - 0s 121us/step - loss: 98.9869 - val_loss: 108.4568\nEpoch 46/50\n404/404 [==============================] - 0s 119us/step - loss: 94.8624 - val_loss: 104.6270\nEpoch 47/50\n404/404 [==============================] - 0s 114us/step - loss: 93.7251 - val_loss: 98.9186\nEpoch 48/50\n404/404 [==============================] - 0s 111us/step - loss: 94.0910 - val_loss: 92.0253\nEpoch 49/50\n404/404 [==============================] - 0s 114us/step - loss: 92.1596 - val_loss: 88.4999\nEpoch 50/50\n404/404 [==============================] - 0s 114us/step - loss: 83.4917 - val_loss: 79.4090\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=d, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 404 samples, validate on 102 samples\nEpoch 1/50\n404/404 [==============================] - 0s 354us/step - loss: 0.6993 - accuracy: 0.0912 - val_loss: 0.6950 - val_accuracy: 0.1071\nEpoch 2/50\n404/404 [==============================] - 0s 89us/step - loss: 0.6738 - accuracy: 0.1114 - val_loss: 0.6742 - val_accuracy: 0.1365\nEpoch 3/50\n404/404 [==============================] - 0s 89us/step - loss: 0.6517 - accuracy: 0.1386 - val_loss: 0.6551 - val_accuracy: 0.1440\nEpoch 4/50\n404/404 [==============================] - 0s 101us/step - loss: 0.6307 - accuracy: 0.1590 - val_loss: 0.6366 - val_accuracy: 0.1659\nEpoch 5/50\n404/404 [==============================] - 0s 87us/step - loss: 0.6097 - accuracy: 0.1750 - val_loss: 0.6183 - val_accuracy: 0.1780\nEpoch 6/50\n404/404 [==============================] - 0s 84us/step - loss: 0.5891 - accuracy: 0.1797 - val_loss: 0.5977 - val_accuracy: 0.1795\nEpoch 7/50\n404/404 [==============================] - 0s 92us/step - loss: 0.5684 - accuracy: 0.1801 - val_loss: 0.5789 - val_accuracy: 0.1810\nEpoch 8/50\n404/404 [==============================] - 0s 89us/step - loss: 0.5502 - accuracy: 0.1803 - val_loss: 0.5631 - val_accuracy: 0.1833\nEpoch 9/50\n404/404 [==============================] - 0s 94us/step - loss: 0.5356 - accuracy: 0.1805 - val_loss: 0.5513 - val_accuracy: 0.1833\nEpoch 10/50\n404/404 [==============================] - 0s 94us/step - loss: 0.5242 - accuracy: 0.1807 - val_loss: 0.5419 - val_accuracy: 0.1833\nEpoch 11/50\n404/404 [==============================] - 0s 94us/step - loss: 0.5147 - accuracy: 0.1807 - val_loss: 0.5335 - val_accuracy: 0.1840\nEpoch 12/50\n404/404 [==============================] - 0s 99us/step - loss: 0.5067 - accuracy: 0.1811 - val_loss: 0.5262 - val_accuracy: 0.1848\nEpoch 13/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4996 - accuracy: 0.1815 - val_loss: 0.5197 - val_accuracy: 0.1848\nEpoch 14/50\n404/404 [==============================] - 0s 97us/step - loss: 0.4932 - accuracy: 0.1811 - val_loss: 0.5135 - val_accuracy: 0.1855\nEpoch 15/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4875 - accuracy: 0.1813 - val_loss: 0.5079 - val_accuracy: 0.1855\nEpoch 16/50\n404/404 [==============================] - 0s 97us/step - loss: 0.4826 - accuracy: 0.1813 - val_loss: 0.5029 - val_accuracy: 0.1863\nEpoch 17/50\n404/404 [==============================] - 0s 106us/step - loss: 0.4782 - accuracy: 0.1816 - val_loss: 0.4988 - val_accuracy: 0.1870\nEpoch 18/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4744 - accuracy: 0.1822 - val_loss: 0.4948 - val_accuracy: 0.1878\nEpoch 19/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4711 - accuracy: 0.1822 - val_loss: 0.4912 - val_accuracy: 0.1870\nEpoch 20/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4682 - accuracy: 0.1826 - val_loss: 0.4878 - val_accuracy: 0.1870\nEpoch 21/50\n404/404 [==============================] - 0s 89us/step - loss: 0.4657 - accuracy: 0.1830 - val_loss: 0.4850 - val_accuracy: 0.1870\nEpoch 22/50\n404/404 [==============================] - 0s 87us/step - loss: 0.4634 - accuracy: 0.1832 - val_loss: 0.4825 - val_accuracy: 0.1870\nEpoch 23/50\n404/404 [==============================] - 0s 84us/step - loss: 0.4614 - accuracy: 0.1834 - val_loss: 0.4802 - val_accuracy: 0.1870\nEpoch 24/50\n404/404 [==============================] - 0s 84us/step - loss: 0.4596 - accuracy: 0.1834 - val_loss: 0.4780 - val_accuracy: 0.1878\nEpoch 25/50\n404/404 [==============================] - 0s 84us/step - loss: 0.4580 - accuracy: 0.1835 - val_loss: 0.4759 - val_accuracy: 0.1878\nEpoch 26/50\n404/404 [==============================] - 0s 104us/step - loss: 0.4564 - accuracy: 0.1835 - val_loss: 0.4743 - val_accuracy: 0.1885\nEpoch 27/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4549 - accuracy: 0.1835 - val_loss: 0.4724 - val_accuracy: 0.1900\nEpoch 28/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4535 - accuracy: 0.1839 - val_loss: 0.4705 - val_accuracy: 0.1900\nEpoch 29/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4521 - accuracy: 0.1839 - val_loss: 0.4688 - val_accuracy: 0.1900\nEpoch 30/50\n404/404 [==============================] - 0s 89us/step - loss: 0.4509 - accuracy: 0.1839 - val_loss: 0.4674 - val_accuracy: 0.1900\nEpoch 31/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4496 - accuracy: 0.1839 - val_loss: 0.4658 - val_accuracy: 0.1900\nEpoch 32/50\n404/404 [==============================] - 0s 89us/step - loss: 0.4484 - accuracy: 0.1839 - val_loss: 0.4642 - val_accuracy: 0.1900\nEpoch 33/50\n404/404 [==============================] - 0s 87us/step - loss: 0.4472 - accuracy: 0.1839 - val_loss: 0.4629 - val_accuracy: 0.1908\nEpoch 34/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4460 - accuracy: 0.1839 - val_loss: 0.4614 - val_accuracy: 0.1900\nEpoch 35/50\n404/404 [==============================] - 0s 84us/step - loss: 0.4448 - accuracy: 0.1839 - val_loss: 0.4600 - val_accuracy: 0.1908\nEpoch 36/50\n404/404 [==============================] - 0s 89us/step - loss: 0.4437 - accuracy: 0.1839 - val_loss: 0.4587 - val_accuracy: 0.1916\nEpoch 37/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4427 - accuracy: 0.1839 - val_loss: 0.4575 - val_accuracy: 0.1916\nEpoch 38/50\n404/404 [==============================] - 0s 89us/step - loss: 0.4416 - accuracy: 0.1839 - val_loss: 0.4561 - val_accuracy: 0.1916\nEpoch 39/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4406 - accuracy: 0.1839 - val_loss: 0.4550 - val_accuracy: 0.1916\nEpoch 40/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4397 - accuracy: 0.1839 - val_loss: 0.4539 - val_accuracy: 0.1916\nEpoch 41/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4387 - accuracy: 0.1839 - val_loss: 0.4528 - val_accuracy: 0.1916\nEpoch 42/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4378 - accuracy: 0.1839 - val_loss: 0.4517 - val_accuracy: 0.1916\nEpoch 43/50\n404/404 [==============================] - 0s 97us/step - loss: 0.4370 - accuracy: 0.1839 - val_loss: 0.4508 - val_accuracy: 0.1916\nEpoch 44/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4361 - accuracy: 0.1839 - val_loss: 0.4500 - val_accuracy: 0.1916\nEpoch 45/50\n404/404 [==============================] - 0s 97us/step - loss: 0.4353 - accuracy: 0.1839 - val_loss: 0.4491 - val_accuracy: 0.1916\nEpoch 46/50\n404/404 [==============================] - 0s 106us/step - loss: 0.4345 - accuracy: 0.1839 - val_loss: 0.4484 - val_accuracy: 0.1916\nEpoch 47/50\n404/404 [==============================] - 0s 94us/step - loss: 0.4338 - accuracy: 0.1841 - val_loss: 0.4475 - val_accuracy: 0.1916\nEpoch 48/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4330 - accuracy: 0.1843 - val_loss: 0.4464 - val_accuracy: 0.1923\nEpoch 49/50\n404/404 [==============================] - 0s 87us/step - loss: 0.4324 - accuracy: 0.1843 - val_loss: 0.4456 - val_accuracy: 0.1923\nEpoch 50/50\n404/404 [==============================] - 0s 92us/step - loss: 0.4317 - accuracy: 0.1843 - val_loss: 0.4448 - val_accuracy: 0.1931\n"
    }
   ],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(Dense(enc_d, input_dim=d, activation=\"relu\", activity_regularizer=l1(10e-5)))\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(d, activation=\"sigmoid\", input_dim=enc_d))\n",
    "\n",
    "auto_enc = Sequential()\n",
    "auto_enc.add(encoder)\n",
    "auto_enc.add(decoder)\n",
    "auto_enc.compile(optimizer=\"adadelta\", loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "hist = auto_enc.fit(X_train, X_train, batch_size=32, epochs=50, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_est = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.        , 2.7750661 , 0.        , 0.12134586, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       1.8331033 , 2.2232275 , 0.        ], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_est[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}